{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"1\" cellpadding=\"5\" cellspacing=\"0\" width=\"100%\">\n",
    "   <tr>\n",
    "      <!--<td align=\"left\" valign=\"top\" width=\"120\"><img src=\"./pictures/octopeek-logo.png\" width=\"120\" /></td>-->\n",
    "      <td align=\"left\" valign=\"top\" width=\"120\"><img src=\"https://media-exp1.licdn.com/dms/image/C510BAQE93sqc09g7qg/company-logo_200_200/0?e=2159024400&v=beta&t=Ebcbl-_mVoiGn-jo8xRX3V0iuAckEhZXnLKcmnOv2Wk\" width=\"120\" /></td>\n",
    "      <td valign=\"top\" width=\"100%\" align=\"center\"><h1><font color=\"blue\">Enseignement d'Intégration - Sujet Octopeek</font></h1>\n",
    "      <p align=\"right\"><h2>Analyse de sentiments sur des Tweets</h2></p>\n",
    "      <p align=\"right\"><h2>date : 08 au 12 juin 2020</p></h2></td>   \n",
    "   </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. e-Reputation et Sentiments Analysis\n",
    "\n",
    "La *Data Science*, l'*Intelligence Artificielle* sont des sujets qui véhiculent énormément de fantasmes. \n",
    "Au-delà du Buzz autours de ces mots, l'objectif d'Octopeek au travers de cet enseignement d'intégration, \n",
    "est de vous faire découvrir ce qui se cache réellement derrière ces mots dans nos entreprises, \n",
    "ainsi que  la manière dont on peut exploiter ces technologies pour garder un avantage singificatif \n",
    "vis-à-vis de la concurrence. \n",
    "\n",
    "<img src=\"./pictures/data-scientist.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contexte\n",
    "\n",
    "\n",
    "La Data Science est la science des données. C’est la discipline qui permet à une entreprise \n",
    "d’explorer et d’analyser les données brutes pour les transformer en informations précieuses \n",
    "permettant de résoudre les problèmes de l’entreprise. L'IA dans ce contexte n'est qu'un outil \n",
    "pour analyser ces données au même titre que par exemple l'analyse numérique. \n",
    "\n",
    "L'analyse de sentiments est un de ces outils utilisé par les entreprises pour améliorer \n",
    "leur efficacité à la fois sur la satisfaction client, mais aussi pour gagner de nouveaux prospects.\n",
    "Comment cela est-il possible ? Prenons un cas concret : une entreprise met sur le marché un nouveau produit.\n",
    "Il se trouve que ce produit est défectueux. Dans un fonctionnement classique, il faudra attendre les retours \n",
    "du service après vente pour constater la présence d'un problème et cela peut prendre du temps, \n",
    "avant que le service lève l'alerte. Or plus le temps passe, plus l'entreprise perd de l'argent \n",
    "(imaginer le coût du rappel des produits) et plus l'image de l'entreprise (sa réputation) peut être remise en cause; \n",
    "et on sait qu'il est très difficile de regagner la confiance des clients une fois celle-ci perdue.\n",
    "\n",
    "La force des GAFAM vient de leur capacité à exploiter ces technologies. Dans notre exemple, \n",
    "l'analyse des retours clients sur les réseaux sociaux, peut permettre à l'entreprise de gaganer un \n",
    "temps précieux en détectant bien en amont du retour SAV le problème sur le produit. \n",
    "Mais pour cela il faut analyser un nombre important de messages utilsateurs sur les réseaux sociaux. \n",
    "Cela n'est pas envisageable \"manuellement\". C'est ici qu'entre-en jeu l'outil \"Analsye des sentiments\".\n",
    "C'est ce qu'exploitent un nombre croissant de vendeurs sur le net, pour réagir au plus vite.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un workflow Datascience\n",
    "\n",
    "C'est à ce stade qu'intervient le *data-scientiste*. Son rôle est de mettre à \n",
    "disposition dans l'entreprise, ces fameux outils autours de la donnée, afin d'aider \n",
    "l'entreprise à (a) gagner en productivité, (b) optimiser ces processus, ou \n",
    "(c) faciliter la prise de décisions.\n",
    "\n",
    "Partant du principe que nous avons déjà au préalable identifié l'opportunité d'exploiter des données \n",
    "pour un sujet clairement identifié, Un workflow assez classique sur un projet Datascience \n",
    "passe par les étapes suivantes \n",
    "    \n",
    "  1. Collecter les données nécesaires\n",
    "  2. Nettoyer et valider les données\n",
    "  3. Tester et/ou élaborer des modèles de datascience  pour extraire l'information pertinente\n",
    "  4. Valider le modèle avant sa mise en production\n",
    "\n",
    "Le projet que nous vous proposons reprend grosso modo ce workflow en le simplifiant \n",
    "pour l'adapter au contexte de cet EI. Le notebook python est l'environnement privilégié \n",
    "du datascientiste dans l'entreprise. C'est pour cela que ce projet sera construit dans un notebook jupyter.\n",
    "La lecture de cet article de blog illustre par exemple l'organisation du travail des datascientistes \n",
    "autours de jupyter chez netflix : [Beyond Interactive: Notebook Innovation at Netflix](https://netflixtechblog.com/notebook-innovation-591ee3221233).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les *Notebooks*\n",
    "\n",
    "Un *notebook* (ou «bloc-notes» en français) est un document créé via l'application Jupyter Notebook, qui contient à la fois du code informatique (python, par exemple) et des éléments de texte enrichis (paragraphes, équations, figures, liens, etc.). Un document *Notebook* est à la fois un document lisible par l'homme contenant la description de l'analyse et les résultats (figures, tableaux, etc.), ainsi qu'un document exécutable par un ordinateur permettant de calculer ou d'effectuer des analyses de données.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "En juillet 2017, l'équipe du Design Lab de l'UC San Diego (cf. l'article <a href=\"https://blog.jupyter.org/we-analyzed-1-million-jupyter-notebooks-now-you-can-too-guest-post-8116a964b536\">We Analyzed 1 Million Jupyter Notebooks — Now You Can Too</a>) a collecté et analysé plus d'un million de blocs-notes Jupyter publiés sur  GitHub. Aujourd'hui, bien qu'ils ne représentent qu'un instantané de l'univers Jupyter, cette étude permet de mieux comprendre la manière dont les utilisateurs utilisent et partagent les blocs-notes Jupyter. L'image ci-dessous illustre un *pattern* fréquent :\n",
    "</div>\n",
    "\n",
    "\n",
    "<img src=\"./pictures/typical-notebook.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Sujet\n",
    "\n",
    "Vous devez collecter des tweets sur un thème ou une entreprise et faire une analyse des données basée sur le sentiment. Pour cela, vous entrainerez un modèle de prédiction de la polarité d'un texte, puis vous analyserez les données que avez collectées avec ce modèle. Vous devez apporter une analyse originale avec valeur ajoutée.\n",
    "\n",
    "Vous êtes libre du sujet mais il doit avoir un objectif précis ainsi que des analyses appronfondies sur des aspects particuliers.\n",
    "\n",
    "Exemples de sujet :\n",
    "\n",
    " * Sentiment sur différents produits Apple (e.g. iPhone, iPad). Vous pouvez aussi proposer d'étudier certaines caractéristiques produits en fonction de la concurrence. Vous pouvez montrer visuallement quels caractéristiques matériels et logicels sont les plus appréciés pour les différentes marques.\n",
    " * Opinions sur les différentes énergies (nucléaire, fossile, renouvelable...) avec une mise en avant de différents arguments dans chaque catégorie. Dans ce cas précis les arguments ne doivent pas être choisis manuellement mais extraits automatiquements. Vous pouvez par exemple présenter des nuages de mots.\n",
    "\n",
    "Comme décrit dans le [pricing Twitter](https://developer.twitter.com/en/pricing), vous n'aurez accès qu'à un historique limité des tweets (7 jours) via L'API search en version gratuite. Vous ne pourrez donc pas faire d'analyse dans le temps, par exemple évaluer le sentiment général d'un produit en faisant une moyenne mois par mois en 2019. Cependant, dans des conditions réelles de développement, si votre projet était destiné à un client, vous auriez pu utiliser le stream Twitter qui vous envoie les tweets en temps réel. Il est alors possible de laisser le stream Twitter tourner sur un de vos serveur pendant plusieurs mois et donc avoir un historique interne de plusieurs mois.\n",
    "\n",
    "Durant cette semaine de projet, vous serez en compétition. Chaque équipe devra fournir une fonction de prédiction de sentiment qui prend en entrée une liste de textes bruts ainsi que le chemin vers un modèle entrainé. La fonction renvoie une polarité pour chaque texte en respectant l'ordre dans la liste donnée en entrée. Cette fonction devra donc faire le prétraitement du texte et renvoyer une liste de nombres (-1, 0, 1). Votre modèle ne sera entrainé sur un seul jeu de données et vous fournirez le notebook (ou script) ayant permis son entrainement ainsi que le jeu de données. Plus de détails seront donnés dans les notebooks suivants. Un score vous sera attribué en fonction des prédictions faites sur notre jeu de données interne. Que la meilleure équipe gagne !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Organisation du projet\n",
    "\n",
    "Chaque équipe nomme un chef d’équipe dont le rôle consiste à :\n",
    "\n",
    " 1. établir avec son équipe un rétro-planning avec le découpage du projet en tâches\n",
    " 2. répartir collégialement et équitablement l’ensemble des tâches en fonction des compétences des membres de son équipe\n",
    " 3. vérifier que le projet avance correctement avec des points réguliers, et en évaluant les risques pendant la durée du projet\n",
    " 4. modifier le cas échéant le planning ou la répartition des tâches\n",
    " 5. Donner l’alerte aux responsables si une difficulté ne peut être surmontée\n",
    "\n",
    "La présence est notée chaque demi-journée en remplissant le tableau de présence sur MS Teams. Les responsables passeront régulièrement dans les canaux des six groupes pour répondre aux questions et vérifier que tout se passe bien.\n",
    "\n",
    "Le projet sera évalué par une note prenant en compte :\n",
    "\n",
    " 1. Le travail d’équipe et l’organisation du travail dans la semaine\n",
    " 2. Les résultats obtenus\n",
    " 3. Le rapport de 5 à 10 pages expliquant le travail effectué\n",
    " 4. La soutenance de 15 minutes par groupe à la fin du projet\n",
    " 5. Les résultats obtenus au challenge\n",
    "  \n",
    "Chaque équipe préparera des questions et évaluera (un classement final donné par chaque équipe) les 5 autres équipes en les classant selon les critères suivants :\n",
    "\n",
    " * Clarté de la présentation (structuration et aisance)\n",
    " * Qualité du travail réalisé (pertinence des choix dans l’analyse des données et de la modélisation, réalisation, consistance des résultats)\n",
    " * Originalité de l’approche adoptée\n",
    " * Capacité à résoudre les difficultés rencontrées\n",
    " * Réponses aux questions (argumentation)\n",
    "\n",
    "Le travail final composé du rapport de 10 pages, des slides de la soutenance et du classement argumenté des équipes sera déposé sur EDUNAO (date limite précisée ultérieurement). Les autres ressources devront être déposées sur les serveurs Jupyter attribués à chaque équipe.\n",
    "\n",
    "##  Programme de la semaine\n",
    "\n",
    "Le projet Eu se déroule du lundi 08 juin au vendredi 12 juin en se basant sur cette approche méthodologique :\n",
    "    \n",
    "<img src=\"./pictures/methodologie.jpg\" />\n",
    "    \n",
    "### Lundi\n",
    "\n",
    "<img src=\"./pictures/step-01.png\" />\n",
    "Compréhension des besoins :\n",
    "    \n",
    " - Définir les objectifs et les thèmes de chaque groupe.\n",
    " - Définir les mesures de réussite.\n",
    " - Identifier les sources de données.\n",
    "\n",
    "<img src=\"./pictures/step-02.png\" />\n",
    "Compréhension & préparation des données :\n",
    "    \n",
    " - Ingérer les données brutes à partir de twitter\n",
    " - Stocker les données en base et l'explorer (visualisation)\n",
    "\n",
    "### Mardi et Mercredi\n",
    "\n",
    "<img src=\"./pictures/step-02.png\" />\n",
    "Suite de la partie \"Compréhension & préparation des données\" :\n",
    "    \n",
    " * Préparation / nettoyages de la donnée\n",
    "\n",
    "<img src=\"./pictures/step-03.png\" />\n",
    "Modélisation & Evaluation :\n",
    "    \n",
    " * Modélisation IA de l'analyse de sentiments sur les tweets\n",
    " * Évaluer\n",
    " * Déterminer la solution « optimale »\n",
    "\n",
    "### Jeudi \n",
    "\n",
    "<img src=\"./pictures/step-04.png\" />\n",
    "Déploiement :\n",
    "    \n",
    " * Faire fonctionner un modèle\n",
    " * Créer des visualisations basées sur les résultats du modèle\n",
    " * Validation / Amélioration / Analyse des résultats\n",
    "\n",
    "### Vendredi \n",
    "\n",
    "  - Présentation des résultats et soutenance.\n",
    "\n",
    "## Livrables\n",
    "\n",
    "Fiche de projet à envoyer le jeudi soir avant minuit nommée EI_ST4_numéro_de_groupe et\n",
    "comportant :\n",
    "\n",
    " * le nom des participants,\n",
    " * les explications sur les choix successifs pour la collecte et l’analyse,\n",
    " * les difficultés rencontrées et les solutions apportées\n",
    "\n",
    "D'autres élements sont à ajouter dans le rapport, vous les trouverez lors de la lecture des notebooks suivants.\n",
    "\n",
    "Les slides (à envoyer avant vendredi midi) pour la soutenance de vendredi après-midi à 13h\n",
    "doivent comporter les éléments suivants :\n",
    "\n",
    " * Introduction : contexte du projet et objectif,\n",
    " * Analyse : selon au moins deux des 5 axes possibles suivants (expliquer les choix effectués et les avantages/inconvénients de chaque solution) :\n",
    "   * collecte des données\n",
    "   * base de training utilisée (Interrogation API, vocabulaire des sentiments, règles métiers,...)\n",
    "   * modèles/algorithmes sélectionnés\n",
    "   * visualisation des données\n",
    "   * enrichissement des données (base, algo, données open source ...)\n",
    " * Implémentation de la solution\n",
    " * Résultats et valeur ajoutée de la solution développée\n",
    " * Difficultés rencontrées\n",
    " * Conclusion\n",
    "\n",
    "Vous uploaderez les notebooks remplis ainsi que les fichiers de données et modèles sauvegardés sur le serveur Jupyter attribué à votre équipe.\n",
    "\n",
    "Vous utilisez les serveur Jupyter librement, nous ferons une relecture du code uniquement à la fin. Afin de vous donner une ouverture plus large sur le \"sentiment analysis\", nous vous proposons de choisir un article scientifique et de le résumer dans ses grandes lignes, à inclure dans le rapport final de l'EI. Vous pouvez en prendre parmis ceux que nous vous envoyons ou en chercher un vous même."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suite...\n",
    "\n",
    "Votre serveur :\n",
    "\n",
    " 1. <http://prod-frm-jupyterhub01.frm.octopeek.com:8001>\n",
    " 2. <http://prod-frm-jupyterhub01.frm.octopeek.com:8002>\n",
    " 3. <http://prod-frm-jupyterhub01.frm.octopeek.com:8003>\n",
    " 4. <http://prod-frm-jupyterhub01.frm.octopeek.com:8004>\n",
    " 5. <http://prod-frm-jupyterhub01.frm.octopeek.com:8005>\n",
    " 6. <http://prod-frm-jupyterhub01.frm.octopeek.com:8006>\n",
    "\n",
    "Vous devez demander le mot de passe de vos serveur sur votre groupe de discussion Teams. Puis uploadez les notebooks fournis sur <https://github.com/hayj/ST4>. Si vous avez besoin d'installer un package, il vous suffit de faire une cellule `!pip install tweepy` (pour installer `tweepy` par exemple) et de l'executer. **Pensez à sauvegarder régulierement vos notebooks et jeux de données pour éviter toute perte (en cas de problème sur les serveurs par exemple).** Si un serveur ne répond plus, il se peut que la RAM soit pleine, vous pouvez demander au responsable un redémarrage de votre serveur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Nous vous conseillons de survoler tous les notebooks afin d'effectuer la répartition des tâches. Lisez bien attentivement les consignes, nous mentionnons certains points qui doivent être introduits dans votre rapport et votre présentation.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
