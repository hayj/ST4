{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"1\" cellpadding=\"5\" cellspacing=\"0\" width=\"100%\">\n",
    "   <tr>\n",
    "      <td align=\"left\" valign=\"top\" width=\"120\"><img src=\"./pictures/octopeek-logo.png\" width=\"120\" /></td>   \n",
    "      <td valign=\"top\" width=\"100%\" align=\"center\"><h1><font color=\"blue\">Enseignement d'Intégration - Sujet Octopeek</font></h1>\n",
    "      <p align=\"right\"><h2>Analyse de sentiments sur des Tweets</h2></p>\n",
    "      <p align=\"right\"><h2>date : 08 au 12 juin 2020</p></h2></td>   \n",
    "   </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. e-Reputation et Sentiments Analysis\n",
    "\n",
    "La *Data Science*, l'*Intelligence Artificielle* sont des sujets qui véhiculent énormément de fantasmes. \n",
    "Au-delà du Buzz autours de ces mots, l'objectif d'Octopeek au travers de cet enseignement d'intégration, \n",
    "est de vous faire découvrir ce qui se cache réellement derrière ces mots dans nos entreprises, \n",
    "ainsi que  la manière dont on peut exploiter ces technologies pour garder un avantage singificatif \n",
    "vis-à-vis de la concurrence. \n",
    "\n",
    "<img src=\"./pictures/data-scientist.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contexte\n",
    "\n",
    "\n",
    "La Data Science est la science des données. C’est la discipline qui permet à une entreprise \n",
    "d’explorer et d’analyser les données brutes pour les transformer en informations précieuses \n",
    "permettant de résoudre les problèmes de l’entreprise. L'IA dans ce contexte n'est qu'un outil \n",
    "pour analyser ces données au même titre que par exemple l'analyse numérique. \n",
    "\n",
    "L'analyse de sentiments est un de ces outils utilisé par les entreprises pour améliorer \n",
    "leur efficacité à la fois sur la satisfaction client, mais aussi pour gagner de nouveaux prospects.\n",
    "Comment cela est-il possible ? Prenons un cas concret : une entreprise met sur le marché un nouveau produit.\n",
    "Il se trouve que ce produit est défectueux. Dans un fonctionnement classique, il faudra attendre les retours \n",
    "du service après vente pour constater la présence d'un problème et cela peut prendre du temps, \n",
    "avant que le service lève l'alerte. Hors plus le temps passe, plus l'entreprise perd de l'argent \n",
    "(imaginer le coût du rappel des produits) et plus l'image de l'entreprise (sa réputation) peut être remise en cause; \n",
    "et on sait qu'il est très difficile de regagner la confiance des clients une fois celle-ci perdue.\n",
    "\n",
    "La force des GAFAM vient de leur capacité à exploiter ces technologies. Dans notre exemple, \n",
    "l'analyse des retours clients sur les réseaux sociaux, peut permettre à l'entreprise de gaganer un \n",
    "temps précieux en détectant bien en amont du retour SAV le problème sur le produit. \n",
    "Mais pour cela il faut analyser un nombre importants de messages utilsateurs sur les réseaux sociaux. \n",
    "Cela n'est pas envisageable \"manuellement\". C'est ici qu'entre-en jeu l'outil \"Analsye des sentiments\".\n",
    "C'est ce qu'exploitent un nombre croissant de vendeurs sur le net, pour réagir au plus vite.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un workflow Datascience\n",
    "\n",
    "C'est à ce stade qu'intervient le *data-scientiste*. Sont rôle est de mettre à \n",
    "disposition dans l'entreprise,  ces fameux outils autours de la données, afin d'aider \n",
    "l'entreprise à (a) gagner en productivité, (b) optimiser ces processus, ou \n",
    "(c) faciliter la prise de décisions.\n",
    "\n",
    "Partant du principe que nous avons déjà au préalable identifié l'opportunité d'exploiter des données \n",
    "pour un sujet clairement identifié, Un workflow assez classique sur un projet Datascience \n",
    "passe par les étapes suivantes \n",
    "    \n",
    "  1. Collecter les données nécesaires\n",
    "  2. Nettoyer et valider les données\n",
    "  3. Tester et/ou élaborer des modèles de datascience  pour extraire l'information pertinente\n",
    "  4. Valider le modèle avant sa mise en production\n",
    "\n",
    "Le projet que nous vous proposons reprend grosso modo ce workflow en le simplifiant \n",
    "pour l'adapter au contexte de cet EI. Le notebook python est l'environnement privilégié \n",
    "du datascientiste dans l'entreprise. C'est pour cela que ce projet sera construit dans unn notebook jupyter.\n",
    "La lecture de cet article de blog illustre par exemple l'organisation du travail des datascientistes \n",
    "autours de jupyter chez netflix : [Beyond Interactive: Notebook Innovation at Netflix](https://netflixtechblog.com/notebook-innovation-591ee3221233).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les *Notebooks*\n",
    "\n",
    "Un *notebooks* (ou «bloc-notes» en français) est un document créé via l'application Jupyter Notebook, qui contiennent à la fois du code informatique (python, par exemple) et des éléments de texte enrichi (paragraphes, équations, figures, liens, etc.). Un document *Notebook* est à la fois un document lisible par l'homme contenant la description de l'analyse et les résultats (figures, tableaux, etc.), ainsi qu'un document exécutable par un ordinateur permettant de calculer ou d'effectuer des analyse de données.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "En juillet 2017, l'équipe du Design Lab de l'UC San Diego (cf. l'article <a href=\"https://blog.jupyter.org/we-analyzed-1-million-jupyter-notebooks-now-you-can-too-guest-post-8116a964b536\">We Analyzed 1 Million Jupyter Notebooks — Now You Can Too</a>) a collecté et analysé plus d'un million de blocs-notes Jupyter publiés sur  GitHub. Aujourd'hui, Bien qu'ils ne représentent qu'un instantané de l'univers Jupyter, cette étude permet de mieux comprendre la manière dont les utilisateurs utilisent et partagent les blocs-notes Jupyter. L'image ci-dessous illustre un *pattern* fréquent :\n",
    "</div>\n",
    "\n",
    "\n",
    "<img src=\"./pictures/typical-notebook.png\" />\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Sujet\n",
    "\n",
    "Vous devez collecter des tweets sur un thème ou une entreprise et faire une analyse des données basé sur le sentiment. Pour cela vous entrainerez un modèle de prédiction de la polarité d'un texte, puis vous analyserez les données que avez collecté avec ce modèle. Vous devez apporter une analyse originale avec valeur ajoutée.\n",
    "\n",
    "Vous êtes libre du sujet mais il doit avoir un objectif précis ainsi que des analyses appronfondies sur des aspects particuliers. Exemples de sujet :\n",
    "\n",
    " * Sentiment sur différents produits Apple avec l'évolution du sentiment sur une série (e.g. l'iPhone) dans le temps. Vous pouvez aussi proposer d'étudier certaines caractéristiques des produits en fonction de la concurrence. Vous pouvez par exemple donner les courbes du ratio positif / (positif + negatif) dans le temps de différents produits ou caractéristiques.\n",
    " * Opinions sur les différentes energies (nucléaire, fossile, renouvelable...) avec une mise en avant de différents arguments dans chaque catégorie. Dans ce cas précis les arguments ne doivent pas être choisis manuellement mais extraits automatiquements. Vous pouvez par exemple présenter des nuages de mots.\n",
    "\n",
    "Vous serez également en compétition. Chaque équipe devra fournir une fonction de prédiction de sentiment qui prend en entrée un texte brut et donne une polarité. Cette fonction devra donc faire le prétraitement du texte et renvoyer un nombre (-1, 0, 1). Votre modèle ne sera entrainé sur un seul jeu de données et vous fournirez le notebook (ou script) ayant permis sont entrainement ainsi que le jeu de données. Plus de détails seront données dans les notebooks suivants. Un score vous sera attribué en fonction des prédictions faites sur notre jeu de données interne. Que la meilleure équipe gagne !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Organisation du projet\n",
    "\n",
    "Chaque équipe nomme un chef d’équipe dont le rôle consiste à :\n",
    "\n",
    " 1. établir avec son équipe un rétro-planning avec le découpage du projet en tâches\n",
    " 2. répartir collégialement et équitablement l’ensemble des tâches en fonction des compétences des membres de son équipe\n",
    " 3. vérifier que le projet avance correctement avec des points réguliers, et en évaluant les risques pendant la durée du projet\n",
    " 4. modifier le cas échéant le planning ou la répartition des tâches\n",
    " 5. Donner l’alerte aux responsables si une difficulté ne peut être surmontée\n",
    "\n",
    "La présence est notée chaque demi-journée en remplissant le tableau de présence sur MS Teams. Les responsables passeront régulièrement dans les canaux des six groupes pour répondre aux questions et vérifier que tout se passe bien.\n",
    "\n",
    "Le projet sera évalué par une note prenant en compte :\n",
    "\n",
    " 1. Le travail d’équipe et l’organisation du travail dans la semaine\n",
    " 2. Les résultats obtenus\n",
    " 3. Le rapport de 5 à 10 pages expliquant le travail effectué\n",
    " 4. La soutenance de 15 minutes par groupe à la fin du projet\n",
    " 5. Les résultats obtenus au challenge\n",
    "  \n",
    "Chaque équipe préparera des questions et évaluera (un classement final donné par chaque équipe) les 5 autres équipes en les classant selon les critères suivants :\n",
    "\n",
    " * Clarté de la présentation (structuration et aisance)\n",
    " * Qualité du travail réalisé (pertinence des choix dans l’analyse des données et de la modélisation, réalisation, consistance des résultats)\n",
    " * Originalité de l’approche adoptée\n",
    " * Capacité à résoudre les difficultés rencontrées\n",
    " * Réponses aux questions (argumentation)\n",
    "\n",
    "Le travail final composé du rapport de 10 pages, des slides de la soutenance et du classement argumenté des équipes sera déposé sur EDUNAO (date limite précisée ultérieurement). Les autres ressources devront être déposés sur les serveurs Jupyter attribués à chaque équipe.\n",
    "\n",
    "##  Programme de la semaine\n",
    "\n",
    "Le projet Eu se déroule du lundi 08 juin au vendredi 12 juin en se basant sur cette approche méthodologique :\n",
    "    \n",
    "<img src=\"./pictures/methodologie.jpg\" />\n",
    "    \n",
    "### Lundi\n",
    "\n",
    "<img src=\"./pictures/step-01.png\" />\n",
    "Compréhension des besoins :\n",
    "    \n",
    " - Définir les objectifs et les thèmes de chaque groupe.\n",
    " - Définir les mesures de réussite.\n",
    " - Identifier les sources de données\n",
    "\n",
    "<img src=\"./pictures/step-02.png\" />\n",
    "Compréhension & préparation des données :\n",
    "    \n",
    " - Ingérer les données brutes à partir de twitter\n",
    " - Stocker les données en base et l'explorer (visualisation)\n",
    "\n",
    "### Mardi et Mercredi\n",
    "\n",
    "<img src=\"./pictures/step-02.png\" />\n",
    "Suite de la partie \"Compréhension & préparation des données\" :\n",
    "    \n",
    " * Préparation / nettoyages de la donnée\n",
    "\n",
    "<img src=\"./pictures/step-03.png\" />\n",
    "Modélisation & Evaluation :\n",
    "    \n",
    " * Modélisation IA de l'analyse de sentiments sur les tweets\n",
    " * Évaluer\n",
    " * Déterminer la solution « optimale »\n",
    "\n",
    "### Jeudi \n",
    "\n",
    "<img src=\"./pictures/step-04.png\" />\n",
    "Déploiement :\n",
    "    \n",
    " * Faire fonctionner un modèle\n",
    " * Créer des visualisations basées sur les résultats du modèle\n",
    " * Validation / Amélioration / Analyse des résultats\n",
    "\n",
    "### Vendredi \n",
    "\n",
    "  - Présentation des résultats et soutenance.\n",
    "\n",
    "## Livrables\n",
    "\n",
    "Fiche de projet à envoyer le jeudi soir avant minuit nommée EI_ST4_numéro_de_groupe et\n",
    "comportant :\n",
    "\n",
    " * le nom des participants,\n",
    " * les explications sur les choix successifs pour la collecte et l’analyse,\n",
    " * les difficultés rencontrées et les solutions apportées\n",
    "\n",
    "D'autres élements sont à ajouter dans le rapport, vous les trouverez lors de la lecture des notebooks suivants.\n",
    "\n",
    "Les slides (à envoyer avant vendredi midi) pour la soutenance de vendredi après-midi à 13h\n",
    "doivent comporter les éléments suivants :\n",
    "\n",
    " * Introduction : contexte du projet et objectif,\n",
    " * Analyse : selon au moins deux des 5 axes possibles suivants (expliquer les choix effectués et les avantages/inconvénients de chaque solution) :\n",
    "   * collecte des données\n",
    "   * base de training utilisée (Interrogation API, vocabulaire des sentiments, règles métiers,...)\n",
    "   * modèles/algorithmes sélectionnés\n",
    "   * visualisation des données\n",
    "   * enrichissement des données (base, algo, données open source ...)\n",
    " * Implémentation de la solution\n",
    " * Résultats et valeur ajoutée de la solution développée\n",
    " * Difficultés rencontrées\n",
    " * Conclusion\n",
    "\n",
    "Vous uploaderez les notebooks remplis ainsi que les fichiers de données et modèles sauvegardés sur le serveur Jupyter attribué à votre équipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
