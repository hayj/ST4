{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"1\" cellpadding=\"5\" cellspacing=\"0\" width=\"100%\">\n",
    "   <tr>\n",
    "      <!--<td align=\"left\" valign=\"top\" width=\"120\"><img src=\"./pictures/octopeek-logo.png\" width=\"120\" /></td>-->\n",
    "      <td align=\"left\" valign=\"top\" width=\"120\"><img src=\"https://media-exp1.licdn.com/dms/image/C510BAQE93sqc09g7qg/company-logo_200_200/0?e=2159024400&v=beta&t=Ebcbl-_mVoiGn-jo8xRX3V0iuAckEhZXnLKcmnOv2Wk\" width=\"120\" /></td>\n",
    "      <td valign=\"top\" width=\"100%\" align=\"center\"><h1><font color=\"blue\">Enseignement d'Intégration - Sujet Octopeek</font></h1>\n",
    "      <p align=\"right\"><h2>Analyse de sentiments sur des Tweets</h2></p>\n",
    "      <p align=\"right\"><h2>date : 08 au 12 juin 2020</p></h2></td>   \n",
    "   </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrainement de modèles\n",
    "\n",
    "Ce notebook a pour objectif de chercher un modèle et une représentation des données optimals ainsi que d'entrainer un modèle final et d'inférer la polarité des tweets de votre projet. Pour la répartition des tâches, n'hésitez pas à remplir le notebook chacun de votre coté, en partageant les fichiers de données, et rassemblez le code dans un notebook final. Vous pouvez dupliquer le notebook sur votre serveur Jupyter puis ne laisser que le final en fin de projet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Toutes les tâches que vous avez sont parallélisables mais également peuvent se faire \"partiellement\" pour que le projet avance. Je donne 2 exemples :<br/>\n",
    "\n",
    "<ul><li>Pour la partie 02-datacollect, vous pouvez créer un premier fichier pickle avec 10 000 tweets, puis vous l'agrandissez au fur et à mesure dans la semaine.</li>\n",
    "<li>Pour la partie 04-models, vous pouvez faire un premier modèle qui fonctionne bien et ainsi inférer les polarités de vos tweets projet, vous pouvez ainsi avancer sur la partie 05-analysis. En parrallèle vous cherchez un meilleur modèle pour le challange en faisant d'autres combinaisons et des recherches d'hyperparamètres. Vous pouvez aussi recommencer votre pipeline de généraion de visuels dans 05-analysis avec de nouvelles prédictions plus précises.</li></ul>\n",
    "\n",
    "L'idée est de commencer les analyses jeudi après-midi maximum. Cette gestion du projet n'est pas simple mais est un bon exercice.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Représentation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La première étape est de transformer les données afin que les modèles *ML* que vous aurez choisi puissent les lire. Il s'agit souvent de transformer les documents en un vecteur représentatif de taille commune. Implémentez 2 ou 3 représentations différentes de vos données. Nous vous conseillons la représentation *TFIDF* ainsi qu'une représentation distributionnelle (Doc2Vec, moyenne des vecteur Word2Vec ou GloVe, inférence d'un modèle pré-entrainé disponible sur internet...). Vous pouvez en trouver une autre et même en choisir une a priori sous-optimale pour comparer. Ayez toujours le réflexe de chercher des bibliothèques avant de coder votre représentation *from scratch*. Si vous choisissez un modèle tel que Doc2Vec, nous vous conseillons d'effectuer un apprentissage non-supervisé avec les données que nous vous fournissons dans le fichier `tweets-for-unsupervised-training.pickle`.\n",
    "\n",
    "Vous décrirez les différents modèles, leur avantages et inconvénients ainsi que vos choix dans le rapport et la présentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ouverture de vos données d'entrainement (fichier `group<X>_<dataname>_preprocessed.pickle`) :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainement non-supervisé OU \"fit\" d'un modèle de représentation OU chargement d'un modèle pré-entrainé :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodage des données du jeu de données annoté :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Les méthodes de traitement automatique du langage naturel dites \"distributionelle\" s'appuient sur l'analyse de grands corpus (ensemble de documents) dans l'objectif d'extraire de la connaissance du texte selon la distribution de chaque mots par rapport aux autres.\n",
    "</div>\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "La machine n'a, contrairement aux humains, aucune connaissance du langage, elle n'est pas capable de trouver de proximité sémantique entre des mots comme \"professeur\" et \"enseignant\". Les lettres que composent ces mots n'apportent aucune information sans connaissance du monde. Une première méthode pour créer des liens entre notions est de créer manuellement un dictionnaire de synonymes, d'ontologies ou autres. Mais la tâche est complexe car le langage est subtil et évolue dans le temps, il est donc plus facile d'inférer des règles ou des relations automatiquement que d'essayer manuellemnt de décrire le langage de facon exhaustive. Les méthodes distributionelles permettent d'exploiter de grands corpus pour automatiquement inférer des similarités entre mots.\n",
    "</div>\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "La sémantique distributionelle se fonde sur l'hypothèse de Harris énnoncé en 1954 : les mots ayant statistiquemet le même contexte seront plus probablement similaire sémantiquement. Concretement, cela signifie que les mots ayant les mêmes voisins dans les phrases sont souvent sémantiquement proches. Par exemple les mots \"voiture\" et \"moto\" sont souvent voisins du verbe \"rouler\", on estimera alors que \"moto\" et \"voiture\" sont sémantiquement proches.\n",
    "</div>\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "Les modèles tel que Word2Vec font en sorte que les vecteurs attribués à \"moto\" et \"voiture\" soient proches d'un point de vue similarité (cosinus...). Pouvoir calculer des simlarités entre mots est important dans la compréhension du langage puisque permet de situer chaque notion par rapport aux autres et ainsi décrire une notion par ses notions proches. Avec les méthodes distributionnelles, les vecteurs de mots sont placés dans un espace vectoriel qui a du sens. Plus recemment, des outils tel que Doc2Vec ou le Deep Learning permettent de représenter des phrases et des documents ayant plus de sens que la simple moyenne des mots.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse qualitative de tweets similaires et dissimilaires\n",
    "\n",
    "Pour chaque modèle de représentation, prennez 10 tweets et affichez le tweets le plus similaire et celui le plus dissimilaire. Vous sauterez une ligne entre chaque triplet. Utilisez par exemple la similarité cosinus. Si le temps de calcul est long, ne comparez un exemple qu'à seulement 1000 autres. Faites une analyse qualitative, commentez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse qualitative :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Une analyse qualitative consiste en l'affichage de quelques exemples afin d'observer que ce que vous calculez correspond à ce que vous attendez. Si vous observez des résultats inattendus, alors votre code est peut-être à revoir.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implémentation des modèles\n",
    "\n",
    "Choisissez 2 modèles minimum dans Scikit-learn. Vous pouvez vous aider de [ce graphe](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) pour choisir. Vous pouvez aussi implementer des modèles avec d'autres librairies si vous pensez avoir le temps.\n",
    "\n",
    "Faites une 10-fold cross-validation de toutes les combinaisons représentation des données / modèles. Pour chaque combinaison vous devez choisir quelques hyperparamètres et effectuer un grid-search pour trouver les meilleurs hyperparamètres. Falcutativement vous pouvez aussi inclure des hyperparamètres qui permettent la génération des représentations (par exemple `min_df` pour *TFIDF*). Vous devez donc utiliser un outil de Scikit-learn qui gère à la fois le grid-search et la cross-validation. Utilisez la métrique *accuracy*. Pour chaque combinaison, affichez le score cv moyen ainsi que les meilleurs hyperparamètres.\n",
    "\n",
    "Vous décrirez les différents modèles, leur avantages et inconvénients ainsi que vos choix dans le rapport et la présentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation des variable `X` et `y` :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid-search :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des meilleurs paramètres et score cv moyen de chaque combinaison :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Il est toujours conseillé d'implementer tout d'abord avec un petit échantillon de vos données afin que les évaluations soient rapides. Vous utiliserez ensuite l'ensemble des données quand tout fonctionnera pour avoir les vrais scores.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faites une analyse qualitative des prédictions de 30 exemples avec le meilleur modèle accessible avec l'attribut `best_estimator_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse qualitative :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Points bonus facultatifs - Librairie *TextBlob*\n",
    "\n",
    "Cette étape peut facilement être faite en parallèle dans un autre notebook. Vous remettrez votre code fonctionnel dans ce notebook. Utilisez la librairie *TextBlob* pour la prédiction de polarité des tweets. *TextBlob* est en quelques sorte un modèle pré-entrainé qui renvoie une polarité à partir d'un texte brut. Vous devez effectuer la même cross-validation (mêmes paramètres, notamment `cv`) en utilisant [cross_validate](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html) et un [estimator custom](https://stackoverflow.com/questions/20330445/how-to-write-a-custom-estimator-in-sklearn-and-use-cross-validation-on-it)) et afficher le score cv moyen. Bien entendu les données ne seront pas les textes encodés mais les textes bruts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installatin de la librairie :\n",
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tableau récapitulatif\n",
    "\n",
    "Créez un tableau récapitulatif en html ou latex (via markdown) rassemblant toutes les combinaisons avec les colonnes :\n",
    "\n",
    " * **Data-repr** (representation des données)\n",
    " * **Model**\n",
    " * **Hyperparameters** (meilleurs hypeparamètres en format court)\n",
    " * **Accuracy** (moyenne des scores cv pour votre métrique accuracy ou autre)\n",
    "\n",
    "Ajoutez *TextBlob* si vous l'avez implementé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tableau (changez le type de cellule) :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement du meilleur modèle sur toutes les données\n",
    "\n",
    "Une fois que vous avez trouvé le meilleur modèle (avec les meilleurs hyperparamètres) et la meilleur représentation, il est important de disposer d'un modèle prédictif ayant toute les chances de généraliser et d'être précis. Pour cela la dernière étape d'un projet ML est d'entrainer le modèle sur toutes les données que nous disposons. Cette étape est souvent oubliée dans la recherche qui se concentre sur le scoring et la comparaison des modèles. Entrainez un modèle sur toutes les données et sauvegardez le. Vous le nommerez `group<X>_<datarepr>_<model>_finalmodel.pickle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainement :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inférence de la polarité sur vos données\n",
    "\n",
    "Reprennez votre fichier `group<X>_<dataname>_projectdata.pickle` de données contenant tous vos tweets. Ce fichier doit normalement contenir une liste de dictionnaires avec les champs `id` et `text` pour chaque élément. Le champs `text` doit correspondre au texte brut non transformé. Vous aurez bien entendu ajouté d'autres champs qui vous sont utiles comme une catégorie ou les mots clefs de requête par exemple.\n",
    "\n",
    "\n",
    "Pour cette étape vous devez créer une fonction `preprocess(text)` qui reprend tout le pipeline de prétraitement du texte brut. Pour chaque tweet, prétraitez son texte brut, puis inférez la polarité avec votre modèle pré-entrainé. Ajouter le champs `predicted_polarity` et re-sérialisez les données sous le même nom de fichier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Désérialisation de votre modèle final :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction `preprocess` :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Certaines étapes de prétraitement sont considérés comme des modèles dans Scikit-learn, vous pouvez alors réutiliser ces \"modèles\" et leur méthode transform afin d'effectuer une transformation de nouveaux exemples. C'est par exemple le cas de TfidfVectorizer.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture des données :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout du champs `predicted_polarity` :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-sérialization du fichier :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faites une analyse qualitative de 30 tweets afin de voir si votre modèle prédit des labels qui vous semblent corrects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse qualitative :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie challenge\n",
    "\n",
    "Pour la partie challenge, nous vous demandons de prendre un fichier `pickle` contenant une liste de tweets et de nous envoyer la polarité de chacun des tweets dans le même ordre. Implémentez ces différentes étapes pour le fichier `trialset.pickle` (jeu de test trial) que vous trouverez sur le repo github. Attention vous devez respecter l'ordre des tweets pour que vos prédictions correspondent à nos labels.\n",
    "\n",
    "Il vous sera demandé, dans un temps très court, d'effectuer les mêmes étapes pour notre vrai fichier d'évaluation (jeu de test) en fin de semaine contenant 900 exemples. Vous devez donc vous assurer que tout fonctionne sur cette partie du notebook. Après la création de votre liste de polarité pickle sur notre jeu de test, vous l'uploaderez sur vos Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ouverture du fichier pickle :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prétraitement de tous les tweets :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inférence des polarités :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sérialisation des polarités (liste d'entier -1, 0, 1 de même taille que le jeu de test) :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suite du projet\n",
    "\n",
    "Vous devez maintenant analyser vos données de projet dans un nouveau notebook qui reprendra votre fichier de données avec les prédictions de polarité. Vous le nommerez `05-analysis.ipynb`.\n",
    "\n",
    " 1. Utilisez <a href=\"https://docs.bokeh.org/en/latest/index.html\">Bokeh</a> ou <a href=\"https://matplotlib.org/\">Matplotlib</a> pour générer des graphes, courbes. Utilisez d'autres librairies pour produire d'autres visuels tels que des nuages de mots.\n",
    " 2. Vous pouvez aussi générer quelques statistiques.\n",
    " 3. Tirer des conclusions à valeur ajoutée, répondez à des interogations comme si vous adressiez à un client, soyez original.\n",
    " 4. Présentez d'autres analyses qui aurait pu être implémentées avec plus de temps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
